{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f077bb6e",
   "metadata": {},
   "source": [
    "**band_pass_filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca7880-712d-452c-a0c9-d0c89c5476c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_data\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Define `bcg_signal` as the data stream representing the BCG signal\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m bcg_signal \u001b[38;5;241m=\u001b[39m \u001b[43mdata_stream\u001b[49m\n\u001b[0;32m     20\u001b[0m filtered_bcg \u001b[38;5;241m=\u001b[39m band_pass_filtering(bcg_signal, fs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbcg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_stream' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on %(25/09/2017)\n",
    "Function to perform a Chebyshev type I bandpass filter for heart rate and breathing.\n",
    "\"\"\"\n",
    "from scipy.signal import cheby1, filtfilt\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def band_pass_filtering(data, fs, filter_type):\n",
    "    if filter_type == \"bcg\":\n",
    "        [b_cheby_high, a_cheby_high] = cheby1(2, 0.5, [2.5 / (fs / 2)], btype='high')\n",
    "        bcg_ = filtfilt(b_cheby_high, a_cheby_high, data)\n",
    "        [b_cheby_low, a_cheby_low] = cheby1(4, 0.5, [5.0 / (fs / 2)], btype='low')\n",
    "        filtered_data = filtfilt(b_cheby_low, a_cheby_low, bcg_)\n",
    "    else:\n",
    "        filtered_data = data\n",
    "    return filtered_data\n",
    "\n",
    "# Load data from the specified file\n",
    "file = r'F:/Study/Data Analytics/Project/dataset/data/01/BCG/01_20231104_BCG.csv'\n",
    "if os.path.exists(file):\n",
    "    rawData = pd.read_csv(file, sep=\",\", header=None, skiprows=1).values\n",
    "    data_stream = rawData[:, 1]  # Extract the data stream column\n",
    "\n",
    "# Define `bcg_signal` as the data stream representing the BCG signal\n",
    "bcg_signal = data_stream\n",
    "\n",
    "filtered_bcg = band_pass_filtering(bcg_signal, fs, \"bcg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def compute_rate(beats, time, mpd):\n",
    "    peaks, _ = find_peaks(beats, distance=mpd)\n",
    "    num_beats = len(peaks)\n",
    "    duration_in_seconds = (time[-1] - time[0]) / 1000\n",
    "    rate = (num_beats / duration_in_seconds) * 60  # bpm\n",
    "    return rate, peaks\n",
    "\n",
    "mpd_samples = int(0.6 * fs)\n",
    "heart_rate, peak_indices = compute_rate(filtered_bcg, time, mpd_samples)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time, filtered_bcg, label='Filtered BCG')\n",
    "# Ensure peak_indices is not empty and is of integer type\n",
    "if len(peak_indices) > 0:\n",
    "    plt.plot(time[peak_indices.astype(int)], filtered_bcg[peak_indices.astype(int)], 'ro', label='Peaks')\n",
    "else:\n",
    "    print(\"No peaks detected in the movement signal.\")\n",
    "plt.title(f\"Detected BCG Peaks - Estimated Heart Rate: {heart_rate:.2f} bpm\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055efe25",
   "metadata": {},
   "source": [
    "**detect_peaks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect peaks in data based on their amplitude and other features.\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "__author__ = \"Marcos Duarte, https://github.com/demotu/BMC\"\n",
    "__version__ = \"1.0.4\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='rising',\n",
    "                 kpsh=False, valley=False, show=False, ax=None):\n",
    "    \"\"\"Detect peaks in data based on their amplitude and other features.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array_like\n",
    "        data.\n",
    "    mph : {None, number}, optional (default = None)\n",
    "        detect peaks that are greater than minimum peak height.\n",
    "    mpd : positive integer, optional (default = 1)\n",
    "        detect peaks that are at least separated by minimum peak distance (in\n",
    "        number of data).\n",
    "    threshold : positive number, optional (default = 0)\n",
    "        detect peaks (valleys) that are greater (smaller) than `threshold`\n",
    "        in relation to their immediate neighbors.\n",
    "    edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
    "        for a flat peak, keep only the rising edge ('rising'), only the\n",
    "        falling edge ('falling'), both edges ('both'), or don't detect a\n",
    "        flat peak (None).\n",
    "    kpsh : bool, optional (default = False)\n",
    "        keep peaks with same height even if they are closer than `mpd`.\n",
    "    valley : bool, optional (default = False)\n",
    "        if True (1), detect valleys (local minima) instead of peaks.\n",
    "    show : bool, optional (default = False)\n",
    "        if True (1), plot data in matplotlib figure.\n",
    "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "    Returns\n",
    "    -------\n",
    "    ind : 1D array_like\n",
    "        indeces of the peaks in `x`.\n",
    "    Notes\n",
    "    -----\n",
    "    The detection of valleys instead of peaks is performed internally by simply\n",
    "    negating the data: `ind_valleys = detect_peaks(-x)`\n",
    "\n",
    "    The function can handle NaN's \n",
    "    See this IPython Notebook [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
    "    Examples\n",
    "    --------\n",
    "    # >>> from detect_peaks import detect_peaks\n",
    "    # >>> x = np.random.randn(100)\n",
    "    # >>> x[60:81] = np.nan\n",
    "    # >>> # detect all peaks and plot data\n",
    "    # >>> ind = detect_peaks(x, show=True)\n",
    "    # >>> print(ind)\n",
    "    # >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    # >>> # set minimum peak height = 0 and minimum peak distance = 20\n",
    "    # >>> detect_peaks(x, mph=0, mpd=20, show=True)\n",
    "    # >>> x = [0, 1, 0, 2, 0, 3, 0, 2, 0, 1, 0]\n",
    "    # >>> # set minimum peak distance = 2\n",
    "    # >>> detect_peaks(x, mpd=2, show=True)\n",
    "    # >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    # >>> # detection of valleys instead of peaks\n",
    "    # >>> detect_peaks(x, mph=0, mpd=20, valley=True, show=True)\n",
    "    # >>> x = [0, 1, 1, 0, 1, 1, 0]\n",
    "    # >>> # detect both edges\n",
    "    # >>> detect_peaks(x, edge='both', show=True)\n",
    "    # >>> x = [-2, 1, -2, 2, 1, 1, 3, 0]\n",
    "    # >>> # set threshold = 2\n",
    "    # >>> detect_peaks(x, threshold = 2, show=True)\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.atleast_1d(x).astype('float64')\n",
    "    if x.size < 3:\n",
    "        return np.array([], dtype=int)\n",
    "    if valley:\n",
    "        x = -x\n",
    "    # find indices of all peaks\n",
    "    dx = x[1:] - x[:-1]\n",
    "    # handle NaN's\n",
    "    indnan = np.where(np.isnan(x))[0]\n",
    "    if indnan.size:\n",
    "        x[indnan] = np.inf\n",
    "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "    if not edge:\n",
    "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "    else:\n",
    "        if edge.lower() in ['rising', 'both']:\n",
    "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        if edge.lower() in ['falling', 'both']:\n",
    "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "    # handle NaN's\n",
    "    if ind.size and indnan.size:\n",
    "        # NaN's and values close to NaN's cannot be peaks\n",
    "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan - 1, indnan + 1))), invert=True)]\n",
    "    # first and last values of x cannot be peaks\n",
    "    if ind.size and ind[0] == 0:\n",
    "        ind = ind[1:]\n",
    "    if ind.size and ind[-1] == x.size - 1:\n",
    "        ind = ind[:-1]\n",
    "    # remove peaks < minimum peak height\n",
    "    if ind.size and mph is not None:\n",
    "        ind = ind[x[ind] >= mph]\n",
    "    # remove peaks - neighbors < threshold\n",
    "    if ind.size and threshold > 0:\n",
    "        dx = np.min(np.vstack([x[ind] - x[ind - 1], x[ind] - x[ind + 1]]), axis=0)\n",
    "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "    # detect small peaks closer than minimum peak distance\n",
    "    if ind.size and mpd > 1:\n",
    "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "        idel = np.zeros(ind.size, dtype=bool)\n",
    "        for i in range(ind.size):\n",
    "            if not idel[i]:\n",
    "                # keep peaks with the same height if kpsh is True\n",
    "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                              & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                idel[i] = 0  # Keep current peak\n",
    "        # remove the small peaks and sort back the indices by their occurrence\n",
    "        ind = np.sort(ind[~idel])\n",
    "\n",
    "    if show:\n",
    "        if indnan.size:\n",
    "            x[indnan] = np.nan\n",
    "        if valley:\n",
    "            x = -x\n",
    "        _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
    "\n",
    "    return ind\n",
    "\n",
    "\n",
    "def _plot(x, mph, mpd, threshold, edge, valley, ax, ind):\n",
    "    \"\"\"Plot results of the detect_peaks function, see its help.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        print('matplotlib is not available.')\n",
    "    else:\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "        ax.plot(x, 'b', lw=1)\n",
    "        if ind.size:\n",
    "            label = 'valley' if valley else 'peak'\n",
    "            label = label + 's' if ind.size > 1 else label\n",
    "            ax.plot(ind, x[ind], '+', mfc=None, mec='r', mew=2, ms=8,\n",
    "                    label='%d %s' % (ind.size, label))\n",
    "            ax.legend(loc='best', framealpha=.5, numpoints=1)\n",
    "        ax.set_xlim(-.02 * x.size, x.size * 1.02 - 1)\n",
    "        ymin, ymax = x[np.isfinite(x)].min(), x[np.isfinite(x)].max()\n",
    "        yrange = ymax - ymin if ymax > ymin else 1\n",
    "        ax.set_ylim(ymin - 0.1 * yrange, ymax + 0.1 * yrange)\n",
    "        ax.set_xlabel('Data #', fontsize=14)\n",
    "        ax.set_ylabel('Amplitude', fontsize=14)\n",
    "        mode = 'Valley detection' if valley else 'Peak detection'\n",
    "        ax.set_title(\"%s (mph=%s, mpd=%d, threshold=%s, edge='%s')\"\n",
    "                     % (mode, str(mph), mpd, str(threshold), edge))\n",
    "        # plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9adb5c",
   "metadata": {},
   "source": [
    "**beat_to_beat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff76fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from detect_peaks import detect_peaks\n",
    "\n",
    "\n",
    "def compute_rate(beats, time, mpd):\n",
    "\n",
    "    indices = detect_peaks(beats, mpd=mpd)\n",
    "\n",
    "    if len(indices) > 1:\n",
    "        peak_to_peak = []\n",
    "        for i in range(0, indices.size - 1):\n",
    "            peak_to_peak = np.append(peak_to_peak, time[indices[i + 1]] - time[indices[i]])\n",
    "        mean_heart_rate = np.average(peak_to_peak, axis=0)\n",
    "        bpm_avg = 1000 * (60 / mean_heart_rate)\n",
    "        return np.round(bpm_avg, decimals=2), indices\n",
    "    else:\n",
    "        return 0.0, 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99010aa3",
   "metadata": {},
   "source": [
    "**compute_vitals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data_subplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb67bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from matplotlib.pyplot import plot, savefig, figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "def normalize(sig):\n",
    "    sig = np.divide(sig, np.sum(np.abs(sig) ** 2, axis=-1) ** (1. / 2))\n",
    "    return sig\n",
    "\n",
    "\n",
    "def data_subplot(raw_data, movement, breathing, dc, t1, t2):\n",
    "    raw_data = normalize(raw_data)\n",
    "    movement = normalize(movement)\n",
    "    breathing = normalize(breathing)\n",
    "    dc = normalize(dc)\n",
    "    steps = np.arange(t1, t2) / 50\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "\n",
    "    ax1.plot(steps, raw_data[t1:t2], lw=2, color='k', label='Raw Signal')\n",
    "    ax1.set_xlabel('Time [Seconds]')\n",
    "    ax1.set_ylabel('Ampltiude')\n",
    "    ax1.legend(bbox_to_anchor=(1, 1.3), loc='center right')\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "\n",
    "    ax2.plot(steps, movement[t1:t2], lw=2, color='k', label='BCG Signal')\n",
    "    ax2.plot(steps, dc[t1:t2], lw=2, color='r', ls='-.', label='Level 4 Smooth')\n",
    "    ax2.set_xlabel('Time [Seconds]')\n",
    "    ax2.set_ylabel('Ampltiude')\n",
    "    ax2.legend(bbox_to_anchor=(1, 1.3), loc='center right')\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "\n",
    "    ax3.plot(steps, breathing[t1:t2], lw=2, color='k', label='Respiratory Signal')\n",
    "    ax3.set_xlabel('Time [Seconds]')\n",
    "    ax3.set_ylabel('Ampltiude')\n",
    "    ax3.legend(bbox_to_anchor=(1, 1.3), loc='center right')\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    \n",
    "    plt.savefig('results\\\\vitals.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b4811",
   "metadata": {},
   "source": [
    "**detect_apnea_events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda432d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on %(25/09/2017)\n",
    "Function to detect apnea events.\n",
    "It returns the start and end time of each detected apnea event\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def unix_time_converter(unix_time):\n",
    "    tm = pd.to_datetime(unix_time, unit='ms')\n",
    "    readable_time = tm.tz_localize('UTC').tz_convert('Asia/Singapore').strftime(\"%H.%M.%S\")\n",
    "    return readable_time\n",
    "\n",
    "\n",
    "def apnea_events(data, utc_time, thresh):\n",
    "    pt1, pt2, win_size = 0, 1500, 1500\n",
    "    hop_size, win_shift = 500, win_size\n",
    "    limit = int(math.floor(data.size / win_size))\n",
    "    counter = 0\n",
    "    start_time, stop_time, apnea_events = [], [], {}\n",
    "    for i in range(0, limit):\n",
    "\n",
    "        StDs = []\n",
    "        sub_data = data[pt1:pt2]\n",
    "        sub_utc_time = utc_time[pt1:pt2]\n",
    "        sub_sub_utc_time = []\n",
    "\n",
    "        for so in range(0, win_shift, hop_size):\n",
    "            ndx = np.arange(so, so + hop_size)\n",
    "            sub_sub_utc_time.append(sub_utc_time[ndx])\n",
    "            fiber_optic_data = sub_data[ndx]\n",
    "\n",
    "            StDs.append(np.std(fiber_optic_data, ddof=1))\n",
    "\n",
    "        T = np.mean(StDs)\n",
    "\n",
    "        ind = [i for i, v in enumerate(StDs) if v <= thresh * T]\n",
    "\n",
    "        if ind:\n",
    "            for j in ind:\n",
    "                counter += 1\n",
    "                current_time = sub_sub_utc_time[j]\n",
    "                start_time.append(unix_time_converter(current_time[0]))\n",
    "                stop_time.append(unix_time_converter(current_time[-1]))\n",
    "                print('\\nApnea Information')\n",
    "                print('start time : ', start_time, ' stop time : ', stop_time)\n",
    "\n",
    "        pt1 = pt2\n",
    "        pt2 += win_size\n",
    "\n",
    "    apnea_events[0] = start_time\n",
    "    apnea_events[1] = stop_time\n",
    "    return apnea_events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015522c8",
   "metadata": {},
   "source": [
    "**detect_body_movements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on %(27/10/2016)\n",
    "Function to detect bed patterns\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from matplotlib.pyplot import plot, savefig, figure\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# The segmentation is performed based on the standard deviation of each time window\n",
    "# In general if the std is less than 15, it means tha the there is no any pressure applied to the mat.\n",
    "# if the std if above 2 * MAD all time-windows SD it means, we are facing body movements.\n",
    "# On the other hand, if the std is between 15 and 2 * MAD of all time-windows SD,\n",
    "# there will be a uniform pressure to the mat. Then, we can analyze the sleep patterns\n",
    "\n",
    "def detect_patterns(pt1, pt2, win_size, data, time, plot):\n",
    "    # store start and end time point\n",
    "    pt1_ = pt1\n",
    "    pt2_ = pt2\n",
    "\n",
    "    limit = int(math.floor(data.size / win_size))\n",
    "    flag = np.zeros([data.size, 1])\n",
    "    event_flags = np.zeros([limit, 1])\n",
    "\n",
    "    segments_sd = []\n",
    "\n",
    "    for i in range(0, limit):\n",
    "        sub_data = data[pt1:pt2]\n",
    "        segments_sd.append(np.std(sub_data, ddof=1))\n",
    "        pt1 = pt2\n",
    "        pt2 += win_size\n",
    "\n",
    "    mad = np.sum(np.abs(segments_sd - np.mean(segments_sd, axis=0))) / (1.0 * len(segments_sd))\n",
    "\n",
    "    thresh1, thresh2 = 15, 2 * mad\n",
    "\n",
    "    pt1, pt2 = pt1_, pt2_\n",
    "\n",
    "    for j in range(0, limit):\n",
    "        std_fos = np.around(segments_sd[j])\n",
    "        if std_fos < thresh1:  # No-movement\n",
    "            flag[pt1:pt2] = 3\n",
    "            event_flags[j] = 3\n",
    "        elif std_fos > thresh2:  # Movement\n",
    "            flag[pt1:pt2] = 2\n",
    "            event_flags[j] = 2\n",
    "        else:\n",
    "            flag[pt1:pt2] = 1  # Sleeping\n",
    "            event_flags[j] = 1\n",
    "        pt1 = pt2\n",
    "        pt2 += win_size\n",
    "\n",
    "    pt1, pt2 = pt1_, pt2_\n",
    "\n",
    "    # Function to highlight activities\n",
    "    data_for_plot = data\n",
    "    width = np.min(data_for_plot)\n",
    "    if width < 0:\n",
    "        height = np.max(data_for_plot) + np.abs(width)\n",
    "    else:\n",
    "        height = np.max(data_for_plot)\n",
    "\n",
    "    if plot == 1:\n",
    "        # fig = plt.figure()\n",
    "        current_axis = plt.gca()\n",
    "        plt.plot(np.arange(0, data.size), data_for_plot, '-k', linewidth=1)\n",
    "        plt.xlabel('Time [Samples]')\n",
    "        plt.ylabel('Amplitude [mV]')\n",
    "        plt.gcf().autofmt_xdate()\n",
    "\n",
    "    for j in range(0, limit):\n",
    "        sub_data = data_for_plot[pt1:pt2]\n",
    "        sub_time = np.arange(pt1, pt2)/50\n",
    "        if event_flags[j] == 3:  # No-movement\n",
    "            if plot == 1:\n",
    "                plt.plot(sub_time, sub_data, '-k', linewidth=1)\n",
    "                current_axis.add_patch(\n",
    "                    Rectangle((pt1, width), win_size, height, facecolor=\"#FAF0BE\", alpha=.2))\n",
    "        elif event_flags[j] == 2:  # Movement\n",
    "            if plot == 1:\n",
    "                plt.plot(sub_time, sub_data, '-k', linewidth=1)\n",
    "                current_axis.add_patch(\n",
    "                    Rectangle((pt1, width), win_size, height, facecolor=\"#FF004F\", alpha=1.0))\n",
    "        else:  # Sleeping\n",
    "            if plot == 1:\n",
    "                plt.plot(sub_time, sub_data, '-k', linewidth=1)\n",
    "                current_axis.add_patch(\n",
    "                    Rectangle((pt1, width), win_size, height, facecolor=\"#00FFFF\", alpha=.2))\n",
    "        pt1 = pt2\n",
    "        pt2 += win_size\n",
    "\n",
    "    plt.savefig('results\\\\rawData.png')\n",
    "\n",
    "    # Remove Body Movements and bed-empty activities\n",
    "    ind2remove = np.sort(np.append(np.where(event_flags == 3), np.where(event_flags == 2)), axis=None)\n",
    "    mask = np.ones(data.size, dtype=bool)\n",
    "    mask[ind2remove] = False\n",
    "    filtered_data = data[mask]\n",
    "    filtered_time = time[mask]\n",
    "\n",
    "    return filtered_data, filtered_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54744f4f",
   "metadata": {},
   "source": [
    "**detect_peaks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect peaks in data based on their amplitude and other features.\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "__author__ = \"Marcos Duarte, https://github.com/demotu/BMC\"\n",
    "__version__ = \"1.0.4\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='rising',\n",
    "                 kpsh=False, valley=False, show=False, ax=None):\n",
    "    \"\"\"Detect peaks in data based on their amplitude and other features.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array_like\n",
    "        data.\n",
    "    mph : {None, number}, optional (default = None)\n",
    "        detect peaks that are greater than minimum peak height.\n",
    "    mpd : positive integer, optional (default = 1)\n",
    "        detect peaks that are at least separated by minimum peak distance (in\n",
    "        number of data).\n",
    "    threshold : positive number, optional (default = 0)\n",
    "        detect peaks (valleys) that are greater (smaller) than `threshold`\n",
    "        in relation to their immediate neighbors.\n",
    "    edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
    "        for a flat peak, keep only the rising edge ('rising'), only the\n",
    "        falling edge ('falling'), both edges ('both'), or don't detect a\n",
    "        flat peak (None).\n",
    "    kpsh : bool, optional (default = False)\n",
    "        keep peaks with same height even if they are closer than `mpd`.\n",
    "    valley : bool, optional (default = False)\n",
    "        if True (1), detect valleys (local minima) instead of peaks.\n",
    "    show : bool, optional (default = False)\n",
    "        if True (1), plot data in matplotlib figure.\n",
    "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "    Returns\n",
    "    -------\n",
    "    ind : 1D array_like\n",
    "        indeces of the peaks in `x`.\n",
    "    Notes\n",
    "    -----\n",
    "    The detection of valleys instead of peaks is performed internally by simply\n",
    "    negating the data: `ind_valleys = detect_peaks(-x)`\n",
    "\n",
    "    The function can handle NaN's \n",
    "    See this IPython Notebook [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
    "    Examples\n",
    "    --------\n",
    "    # >>> from detect_peaks import detect_peaks\n",
    "    # >>> x = np.random.randn(100)\n",
    "    # >>> x[60:81] = np.nan\n",
    "    # >>> # detect all peaks and plot data\n",
    "    # >>> ind = detect_peaks(x, show=True)\n",
    "    # >>> print(ind)\n",
    "    # >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    # >>> # set minimum peak height = 0 and minimum peak distance = 20\n",
    "    # >>> detect_peaks(x, mph=0, mpd=20, show=True)\n",
    "    # >>> x = [0, 1, 0, 2, 0, 3, 0, 2, 0, 1, 0]\n",
    "    # >>> # set minimum peak distance = 2\n",
    "    # >>> detect_peaks(x, mpd=2, show=True)\n",
    "    # >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    # >>> # detection of valleys instead of peaks\n",
    "    # >>> detect_peaks(x, mph=0, mpd=20, valley=True, show=True)\n",
    "    # >>> x = [0, 1, 1, 0, 1, 1, 0]\n",
    "    # >>> # detect both edges\n",
    "    # >>> detect_peaks(x, edge='both', show=True)\n",
    "    # >>> x = [-2, 1, -2, 2, 1, 1, 3, 0]\n",
    "    # >>> # set threshold = 2\n",
    "    # >>> detect_peaks(x, threshold = 2, show=True)\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.atleast_1d(x).astype('float64')\n",
    "    if x.size < 3:\n",
    "        return np.array([], dtype=int)\n",
    "    if valley:\n",
    "        x = -x\n",
    "    # find indices of all peaks\n",
    "    dx = x[1:] - x[:-1]\n",
    "    # handle NaN's\n",
    "    indnan = np.where(np.isnan(x))[0]\n",
    "    if indnan.size:\n",
    "        x[indnan] = np.inf\n",
    "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "    if not edge:\n",
    "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "    else:\n",
    "        if edge.lower() in ['rising', 'both']:\n",
    "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        if edge.lower() in ['falling', 'both']:\n",
    "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "    # handle NaN's\n",
    "    if ind.size and indnan.size:\n",
    "        # NaN's and values close to NaN's cannot be peaks\n",
    "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan - 1, indnan + 1))), invert=True)]\n",
    "    # first and last values of x cannot be peaks\n",
    "    if ind.size and ind[0] == 0:\n",
    "        ind = ind[1:]\n",
    "    if ind.size and ind[-1] == x.size - 1:\n",
    "        ind = ind[:-1]\n",
    "    # remove peaks < minimum peak height\n",
    "    if ind.size and mph is not None:\n",
    "        ind = ind[x[ind] >= mph]\n",
    "    # remove peaks - neighbors < threshold\n",
    "    if ind.size and threshold > 0:\n",
    "        dx = np.min(np.vstack([x[ind] - x[ind - 1], x[ind] - x[ind + 1]]), axis=0)\n",
    "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "    # detect small peaks closer than minimum peak distance\n",
    "    if ind.size and mpd > 1:\n",
    "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "        idel = np.zeros(ind.size, dtype=bool)\n",
    "        for i in range(ind.size):\n",
    "            if not idel[i]:\n",
    "                # keep peaks with the same height if kpsh is True\n",
    "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                              & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                idel[i] = 0  # Keep current peak\n",
    "        # remove the small peaks and sort back the indices by their occurrence\n",
    "        ind = np.sort(ind[~idel])\n",
    "\n",
    "    if show:\n",
    "        if indnan.size:\n",
    "            x[indnan] = np.nan\n",
    "        if valley:\n",
    "            x = -x\n",
    "        _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
    "\n",
    "    return ind\n",
    "\n",
    "\n",
    "def _plot(x, mph, mpd, threshold, edge, valley, ax, ind):\n",
    "    \"\"\"Plot results of the detect_peaks function, see its help.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        print('matplotlib is not available.')\n",
    "    else:\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "        ax.plot(x, 'b', lw=1)\n",
    "        if ind.size:\n",
    "            label = 'valley' if valley else 'peak'\n",
    "            label = label + 's' if ind.size > 1 else label\n",
    "            ax.plot(ind, x[ind], '+', mfc=None, mec='r', mew=2, ms=8,\n",
    "                    label='%d %s' % (ind.size, label))\n",
    "            ax.legend(loc='best', framealpha=.5, numpoints=1)\n",
    "        ax.set_xlim(-.02 * x.size, x.size * 1.02 - 1)\n",
    "        ymin, ymax = x[np.isfinite(x)].min(), x[np.isfinite(x)].max()\n",
    "        yrange = ymax - ymin if ymax > ymin else 1\n",
    "        ax.set_ylim(ymin - 0.1 * yrange, ymax + 0.1 * yrange)\n",
    "        ax.set_xlabel('Data #', fontsize=14)\n",
    "        ax.set_ylabel('Amplitude', fontsize=14)\n",
    "        mode = 'Valley detection' if valley else 'Peak detection'\n",
    "        ax.set_title(\"%s (mph=%s, mpd=%d, threshold=%s, edge='%s')\"\n",
    "                     % (mode, str(mph), mpd, str(threshold), edge))\n",
    "        # plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c3e6f",
   "metadata": {},
   "source": [
    "**modwt_matlab_fft**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a88fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on %(31/08/2016)\n",
    "Program to compute Maximal Overlap Discrete Wavelet Transform\n",
    "Equivalent to Matlab modwt\n",
    "\"\"\"\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pyfftw\n",
    "import pywt\n",
    "\n",
    "\n",
    "def modwt(x, wname, J):\n",
    "    # % Convert data to row vector\n",
    "    if x.shape[0] > 1:\n",
    "        x = x.flatten()\n",
    "\n",
    "    # % Record original data length\n",
    "    datalength = x.size\n",
    "\n",
    "    # % Check that the level of the transform does not exceed floor(log2(len(x))\n",
    "    Jmax = np.floor(math.log(datalength, 2))\n",
    "    if J <= 0 or J > Jmax:\n",
    "        print('Wavelet:modwt:MRALevel')\n",
    "        sys.exit()\n",
    "\n",
    "    # % obtain new signal length if needed\n",
    "    siglen = x.size\n",
    "    Nrep = siglen\n",
    "\n",
    "    # % Scale the scaling and wavelet filters for the MODWT\n",
    "    wavelet = pywt.Wavelet(wname)\n",
    "    Lo = wavelet.rec_lo\n",
    "    Hi = wavelet.rec_hi\n",
    "    Lo = np.array(Lo) / np.sqrt(2)\n",
    "    Hi = np.array(Hi) / np.sqrt(2)\n",
    "\n",
    "    # % Ensure Lo and Hi are row vectors\n",
    "    if Lo.shape[0] > 1:\n",
    "        Lo = Lo.flatten()\n",
    "    if Hi.shape[0] > 1:\n",
    "        Hi = Hi.flatten()\n",
    "\n",
    "    # % If the signal length is less than the filter length, need to\n",
    "    # % periodize the signal in order to use the DFT algorithm\n",
    "    if siglen < len(Lo):\n",
    "        xp = np.tile(x, (1, len(Lo) - siglen))\n",
    "        x = np.append(x, xp)\n",
    "        Nrep = x.size\n",
    "\n",
    "    # % Allocate coefficient array\n",
    "    w = []  # np.zeros(shape=(J + 1, Nrep))\n",
    "\n",
    "    # % Obtain the DFT of the filters\n",
    "    G = pyfftw.interfaces.numpy_fft.fft(Lo, Nrep, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "    H = pyfftw.interfaces.numpy_fft.fft(Hi, Nrep, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "\n",
    "    # %Obtain the DFT of the data\n",
    "    Vhat = pyfftw.interfaces.numpy_fft.fft(x, planner_effort='FFTW_ESTIMATE').T\n",
    "\n",
    "    # % [Vhat,What] = modwtfft(X,G,H,J)\n",
    "    def modwtdec(X, G, H, J):\n",
    "        N = X.size\n",
    "        upfactor = 2 ** J\n",
    "        Gup = G[np.mod(upfactor * np.arange(0, N), N)]\n",
    "        Hup = H[np.mod(upfactor * np.arange(0, N), N)]\n",
    "        Vhat = np.multiply(Gup, X)\n",
    "        What = np.multiply(Hup, X)\n",
    "        return Vhat, What\n",
    "\n",
    "    # % Main MODWT algorithm\n",
    "    for jj in range(J):\n",
    "        [Vhat, What] = modwtdec(Vhat, G, H, jj)\n",
    "        w.append(pyfftw.interfaces.numpy_fft.ifft(What, planner_effort='FFTW_ESTIMATE', threads=1).real)\n",
    "    w.append(pyfftw.interfaces.numpy_fft.ifft(Vhat, planner_effort='FFTW_ESTIMATE', threads=1).real)\n",
    "    w = np.vstack(w)\n",
    "    w = w[:, 0:siglen]\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375efd44",
   "metadata": {},
   "source": [
    "**modwt_mra_matlab_fft**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fa367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on %(31/08/2016)\n",
    "Program to compute Maximal Overlap Discrete Wavelet Transform\n",
    "Equivalent to Matlab modwt\n",
    "\"\"\"\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pyfftw\n",
    "import pywt\n",
    "\n",
    "\n",
    "def modwt(x, wname, J):\n",
    "    # % Convert data to row vector\n",
    "    if x.shape[0] > 1:\n",
    "        x = x.flatten()\n",
    "\n",
    "    # % Record original data length\n",
    "    datalength = x.size\n",
    "\n",
    "    # % Check that the level of the transform does not exceed floor(log2(len(x))\n",
    "    Jmax = np.floor(math.log(datalength, 2))\n",
    "    if J <= 0 or J > Jmax:\n",
    "        print('Wavelet:modwt:MRALevel')\n",
    "        sys.exit()\n",
    "\n",
    "    # % obtain new signal length if needed\n",
    "    siglen = x.size\n",
    "    Nrep = siglen\n",
    "\n",
    "    # % Scale the scaling and wavelet filters for the MODWT\n",
    "    wavelet = pywt.Wavelet(wname)\n",
    "    Lo = wavelet.rec_lo\n",
    "    Hi = wavelet.rec_hi\n",
    "    Lo = np.array(Lo) / np.sqrt(2)\n",
    "    Hi = np.array(Hi) / np.sqrt(2)\n",
    "\n",
    "    # % Ensure Lo and Hi are row vectors\n",
    "    if Lo.shape[0] > 1:\n",
    "        Lo = Lo.flatten()\n",
    "    if Hi.shape[0] > 1:\n",
    "        Hi = Hi.flatten()\n",
    "\n",
    "    # % If the signal length is less than the filter length, need to\n",
    "    # % periodize the signal in order to use the DFT algorithm\n",
    "    if siglen < len(Lo):\n",
    "        xp = np.tile(x, (1, len(Lo) - siglen))\n",
    "        x = np.append(x, xp)\n",
    "        Nrep = x.size\n",
    "\n",
    "    # % Allocate coefficient array\n",
    "    w = []  # np.zeros(shape=(J + 1, Nrep))\n",
    "\n",
    "    # % Obtain the DFT of the filters\n",
    "    G = pyfftw.interfaces.numpy_fft.fft(Lo, Nrep, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "    H = pyfftw.interfaces.numpy_fft.fft(Hi, Nrep, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "\n",
    "    # %Obtain the DFT of the data\n",
    "    Vhat = pyfftw.interfaces.numpy_fft.fft(x, planner_effort='FFTW_ESTIMATE').T\n",
    "\n",
    "    # % [Vhat,What] = modwtfft(X,G,H,J)\n",
    "    def modwtdec(X, G, H, J):\n",
    "        N = X.size\n",
    "        upfactor = 2 ** J\n",
    "        Gup = G[np.mod(upfactor * np.arange(0, N), N)]\n",
    "        Hup = H[np.mod(upfactor * np.arange(0, N), N)]\n",
    "        Vhat = np.multiply(Gup, X)\n",
    "        What = np.multiply(Hup, X)\n",
    "        return Vhat, What\n",
    "\n",
    "    # % Main MODWT algorithm\n",
    "    for jj in range(J):\n",
    "        [Vhat, What] = modwtdec(Vhat, G, H, jj)\n",
    "        w.append(pyfftw.interfaces.numpy_fft.ifft(What, planner_effort='FFTW_ESTIMATE', threads=1).real)\n",
    "    w.append(pyfftw.interfaces.numpy_fft.ifft(Vhat, planner_effort='FFTW_ESTIMATE', threads=1).real)\n",
    "    w = np.vstack(w)\n",
    "    w = w[:, 0:siglen]\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1095a0",
   "metadata": {},
   "source": [
    "**modwt_mra_matlab_fft**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e54752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on %(31/08/2016)\n",
    "Program to compute Multi-Resolution Analysis / Maximal Overlap Discrete Wavelet Transform\n",
    "Equivalent to Matlab modwtmra\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pyfftw\n",
    "import pywt\n",
    "\n",
    "\n",
    "def modwtmra(w, wname):\n",
    "    # % The input to modwtmra must be a matrix\n",
    "    if w.shape[0] == 1 and w.shape[1] > 1 or w.shape[0] > 1 and w.shape[1] == 1:\n",
    "        print('Wavelet:modwt:MRASize')\n",
    "        sys.exit()\n",
    "\n",
    "    # % get the size of the output coefficients\n",
    "    cfslength = w.shape[1]\n",
    "    J0 = w.shape[0] - 1\n",
    "\n",
    "    nullinput = np.zeros(cfslength)\n",
    "    N = cfslength\n",
    "\n",
    "    # % Scale the scaling and wavelet filters for the MODWT\n",
    "    wavelet = pywt.Wavelet(wname)\n",
    "    Lo = wavelet.rec_lo\n",
    "    Hi = wavelet.rec_hi\n",
    "    Lo = np.array(Lo) / np.sqrt(2)\n",
    "    Hi = np.array(Hi) / np.sqrt(2)\n",
    "\n",
    "    if cfslength < len(Lo):\n",
    "        wp = np.tile(w, (1, len(Lo) - cfslength))\n",
    "        w = np.append(w, wp, axis=1)\n",
    "        cfslength = w.shape[1]\n",
    "        nullinput = np.zeros(cfslength)\n",
    "\n",
    "    G = pyfftw.interfaces.numpy_fft.fft(Lo, cfslength, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "    H = pyfftw.interfaces.numpy_fft.fft(Hi, cfslength, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "\n",
    "    # % Allocate array for MRA\n",
    "    mra = []  # np.zeros(shape=(J0 + 1, N))\n",
    "\n",
    "    def imodwtrec(Vin, Win, G, H, J):\n",
    "        N = Vin.size\n",
    "        Vhat = pyfftw.interfaces.numpy_fft.fft(Vin, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "        What = pyfftw.interfaces.numpy_fft.fft(Win, planner_effort='FFTW_ESTIMATE', threads=1).T\n",
    "        upfactor = 2 ** J\n",
    "        Gup = np.conj(G[np.mod(upfactor * np.arange(0, N), N)])\n",
    "        Hup = np.conj(H[np.mod(upfactor * np.arange(0, N), N)])\n",
    "        Vout = pyfftw.interfaces.numpy_fft.ifft(np.multiply(Gup, Vhat) + np.multiply(Hup, What),\n",
    "                                                planner_effort='FFTW_ESTIMATE', threads=1).real\n",
    "        return Vout\n",
    "\n",
    "    def imodwtDetails(coefs, nullinput, lev, Lo, Hi, N):\n",
    "        v = nullinput\n",
    "        w = coefs\n",
    "        for jj in range(lev + 1, 0, -1):\n",
    "            vout = imodwtrec(v, w, Lo, Hi, jj - 1)\n",
    "            w = nullinput\n",
    "            v = vout\n",
    "        details = v[0:N]\n",
    "        return details\n",
    "\n",
    "    def imodwtSmooth(scalingcoefs, nullinput, Lo, Hi, N, J0):\n",
    "        v = scalingcoefs\n",
    "        for J in range(J0 + 1, 0, -1):\n",
    "            vout = imodwtrec(v, nullinput, Lo, Hi, J - 1)\n",
    "            v = vout\n",
    "        smooth = v[0:N]\n",
    "        return smooth\n",
    "\n",
    "    # % Main MRA - MODWT algorithm\n",
    "    for J in range(J0, 0, -1):\n",
    "        wcfs = w[J - 1]\n",
    "        details = imodwtDetails(wcfs, nullinput, J - 1, G, H, cfslength)\n",
    "        details = details[0:N]\n",
    "        mra.append(details)\n",
    "    scalingcoefs = w[J0:]\n",
    "    smooth = imodwtSmooth(scalingcoefs.flatten(), nullinput, G, H, cfslength, J0 - 1)\n",
    "    mra = mra[::-1]\n",
    "    mra.append(smooth[0: N])\n",
    "    mra = np.vstack(mra)\n",
    "    return mra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89940152",
   "metadata": {},
   "source": [
    "**remove_nonLinear_trend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on %(25/09/2017)\n",
    "Function to remove nonlinear trend.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def remove_nonLinear_trend(input_signal, order):\n",
    "    # Detrend with a n order polynomial\n",
    "    model = np.polyfit(np.arange(0, input_signal.size), input_signal, order)\n",
    "    predicted = np.polyval(model, np.arange(0, input_signal.size))\n",
    "    filteredSignal = input_signal - predicted\n",
    "    return filteredSignal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a74b9",
   "metadata": {},
   "source": [
    "**main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start processing ...\n",
      "Total data length before cleaning: 3643008\n",
      "Number of NaN values in data_stream: 3643007\n",
      "Number of NaN values in utc_time: 0\n",
      "Data Stream after imputation: [1.69902211e+12]\n",
      "Cleaned Data Stream: [1.69902211e+12]\n",
      "Cleaned UTC Time: [-86.]\n",
      "Error: Insufficient data for processing. Data length: 1\n",
      "Please check the input file for missing or invalid data.\n",
      "Warning: Data is too sparse for meaningful processing.\n",
      "Filling remaining NaN values with the mean of the data.\n",
      "Error: Insufficient data for processing even after fallback imputation.\n",
      "Please check the input file or use a different dataset.\n",
      "Error: Insufficient data for processing. Data length: 1\n",
      "Please check the input file for missing or invalid data.\n",
      "Data Stream: [1.69902211e+12]\n",
      "UTC Time: [-86.]\n",
      "Warning: Input data length (1) is too short for filtering. Returning unfiltered data.\n",
      "Movement Signal: [1.69902211e+12]\n",
      "Total data length before cleaning: 3643008\n",
      "Number of NaN values in data_stream: 3643007\n",
      "Number of NaN values in utc_time: 0\n",
      "Data Stream after imputation: [1.69902211e+12]\n",
      "Cleaned Data Stream: [1.69902211e+12]\n",
      "Cleaned UTC Time: [-86.]\n",
      "Error: Insufficient data for processing. Data length: 1\n",
      "Please check the input file for missing or invalid data.\n",
      "Warning: Data is too sparse for meaningful processing.\n",
      "Filling remaining NaN values with the mean of the data.\n",
      "Error: Insufficient data for processing even after fallback imputation.\n",
      "Please check the input file or use a different dataset.\n",
      "Error: Insufficient data for processing. Data length: 1\n",
      "Please check the input file for missing or invalid data.\n",
      "Data Stream: [1.69902211e+12]\n",
      "UTC Time: [-86.]\n",
      "Warning: Input data length (1) is too short for filtering. Returning unfiltered data.\n",
      "Movement Signal: [1.69902211e+12]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 167\u001b[0m\n\u001b[0;32m    165\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m    166\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(time, movement, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiltered BCG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 167\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtime\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeak_indices\u001b[49m\u001b[43m]\u001b[49m, movement[peak_indices], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mro\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeaks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    168\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected BCG Peaks - Estimated Heart Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheart_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bpm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    169\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime (ms)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from band_pass_filtering import band_pass_filtering\n",
    "from compute_vitals import vitals\n",
    "from beat_to_beat import compute_rate\n",
    "\n",
    "from detect_apnea_events import apnea_events\n",
    "from detect_body_movements import detect_patterns\n",
    "from modwt_matlab_fft import modwt\n",
    "from modwt_mra_matlab_fft import modwtmra\n",
    "from remove_nonLinear_trend import remove_nonLinear_trend\n",
    "from data_subplot import data_subplot\n",
    "# ======================================================================================================================\n",
    "\n",
    "# Main program starts here\n",
    "print('\\nstart processing ...')\n",
    "\n",
    "file = r'F:/Study/Data Analytics/Project/dataset/data/01/BCG/01_20231104_BCG.csv'\n",
    "\n",
    "if file.endswith(\".csv\"):\n",
    "    if os.path.exists(file):\n",
    "        fileName = os.path.join(file)\n",
    "        if os.stat(fileName).st_size != 0:\n",
    "            rawData = pd.read_csv(fileName, sep=\",\", header=None, skiprows=1).values\n",
    "            utc_time = rawData[:, 0]\n",
    "            data_stream = rawData[:, 1]\n",
    "\n",
    "            # Debugging: Print the number of NaN values and total data length\n",
    "            print(\"Total data length before cleaning:\", len(rawData))\n",
    "            print(\"Number of NaN values in data_stream:\", np.isnan(data_stream).sum())\n",
    "            print(\"Number of NaN values in utc_time:\", np.isnan(utc_time).sum())\n",
    "\n",
    "            # Remove rows with NaN values\n",
    "            valid_indices = ~np.isnan(data_stream) & ~np.isnan(utc_time)\n",
    "            data_stream = data_stream[valid_indices]\n",
    "            utc_time = utc_time[valid_indices]\n",
    "\n",
    "            # Impute missing data in data_stream\n",
    "            if np.isnan(data_stream).sum() > 0:\n",
    "                print(\"Imputing missing data in data_stream...\")\n",
    "                data_stream = pd.Series(data_stream).interpolate(method='linear', limit_direction='both').to_numpy()\n",
    "\n",
    "            # Debugging: Print data after imputation\n",
    "            print(\"Data Stream after imputation:\", data_stream[:10])\n",
    "\n",
    "            # Debugging: Print cleaned data\n",
    "            print(\"Cleaned Data Stream:\", data_stream[:10])\n",
    "            print(\"Cleaned UTC Time:\", utc_time[:10])\n",
    "\n",
    "            # Define sampling frequency\n",
    "            fs = 50  # Example value, adjust as needed\n",
    "\n",
    "            # Check if the data length is sufficient for processing\n",
    "            if len(data_stream) <= 9:\n",
    "                print(\"Error: Insufficient data for processing. Data length:\", len(data_stream))\n",
    "                print(\"Please check the input file for missing or invalid data.\")\n",
    "                exit()  # Terminate the program gracefully\n",
    "\n",
    "            # Check if the data is too sparse after imputation\n",
    "            if len(data_stream) <= 9:  # Pad length for filtering is 9\n",
    "                print(\"Warning: Data is too sparse for meaningful processing.\")\n",
    "                print(\"Filling remaining NaN values with the mean of the data.\")\n",
    "                data_stream = np.nan_to_num(data_stream, nan=np.nanmean(data_stream))\n",
    "\n",
    "            # Re-check if the data is sufficient after fallback imputation\n",
    "            if len(data_stream) <= 9:\n",
    "                print(\"Error: Insufficient data for processing even after fallback imputation.\")\n",
    "                print(\"Please check the input file or use a different dataset.\")\n",
    "                exit()  # Terminate the program gracefully\n",
    "\n",
    "            # Initialize variables for the vitals function\n",
    "            t1 = 0  # Starting point for the window\n",
    "            t2 = 500  # Ending point for the window\n",
    "            window_shift = 500  # Shift size for the window\n",
    "            limit = int(math.floor(len(data_stream) / window_shift))  # Calculate the limit based on data length\n",
    "\n",
    "            # Check if the data is sufficient for processing\n",
    "            if len(data_stream) <= 9:  # Pad length for filtering is 9\n",
    "                print(\"Error: Insufficient data for processing. Data length:\", len(data_stream))\n",
    "                print(\"Please check the input file for missing or invalid data.\")\n",
    "                # Skip further processing if data is insufficient\n",
    "                exit()  # Terminate the program gracefully\n",
    "            else:\n",
    "                start_point, end_point, window_shift = 0, 500, 500\n",
    "                # ==========================================================================================================\n",
    "                data_stream, utc_time = detect_patterns(start_point, end_point, window_shift, data_stream, utc_time, plot=1)\n",
    "                # ==========================================================================================================\n",
    "                # BCG signal extraction\n",
    "                movement = band_pass_filtering(data_stream, fs, \"bcg\")\n",
    "                # ==========================================================================================================\n",
    "                # Respiratory signal extraction\n",
    "                breathing = band_pass_filtering(data_stream, fs, \"breath\")\n",
    "                breathing = remove_nonLinear_trend(breathing, 3)\n",
    "                breathing = savgol_filter(breathing, 11, 3)\n",
    "                # ==========================================================================================================\n",
    "                # Compute wavelet decomposition and extract wavelet cycle\n",
    "                w = modwt(movement, 'bior3.9', 4)  # Perform MODWT on the movement signal\n",
    "                dc = modwtmra(w, 'bior3.9')  # Perform MRA to extract components\n",
    "                wavelet_cycle = dc[3]  # Extract the desired wavelet cycle (adjust index as needed)\n",
    "                # ==========================================================================================================\n",
    "                # Vital Signs estimation - (10 seconds window is an optimal size for vital signs measurement)\n",
    "                t1, t2, window_length, window_shift = 0, 500, 500, 500\n",
    "                hop_size = math.floor((window_length - 1) / 2)\n",
    "                limit = int(math.floor(breathing.size / window_shift))\n",
    "                # ==========================================================================================================\n",
    "                # Initialize variables for the vitals function\n",
    "                # Define the starting and ending points for the window\n",
    "                # Define the window shift and limit based on the data length\n",
    "\n",
    "                t1 = 0  # Starting point for the window\n",
    "                t2 = 500  # Ending point for the window\n",
    "                window_shift = 500  # Shift size for the window\n",
    "                limit = int(math.floor(len(data_stream) / window_shift))  # Calculate the limit based on data length\n",
    "\n",
    "                # Heart Rate\n",
    "                beats = vitals(t1, t2, window_shift, limit, wavelet_cycle, utc_time, mpd=1, plot=0)\n",
    "                print('\\nHeart Rate Information')\n",
    "                print('Minimum pulse : ', np.around(np.min(beats)))\n",
    "                print('Maximum pulse : ', np.around(np.max(beats)))\n",
    "                print('Average pulse : ', np.around(np.mean(beats)))\n",
    "                # Breathing Rate\n",
    "                beats = vitals(t1, t2, window_shift, limit, breathing, utc_time, mpd=1, plot=0)\n",
    "                print('\\nRespiratory Rate Information')\n",
    "                print('Minimum breathing : ', np.around(np.min(beats)))\n",
    "                print('Maximum breathing : ', np.around(np.max(beats)))\n",
    "                print('Average breathing : ', np.around(np.mean(beats)))\n",
    "                # ==============================================================================================================\n",
    "                thresh = 0.3\n",
    "                events = apnea_events(breathing, utc_time, thresh=thresh)\n",
    "                # ==============================================================================================================\n",
    "                # Plot Vitals Example\n",
    "                t1, t2 = 2500, 2500 * 2\n",
    "                data_subplot(data_stream, movement, breathing, wavelet_cycle, t1, t2)\n",
    "                # ==============================================================================================================\n",
    "\n",
    "\n",
    "    print(\"Data Stream:\", data_stream[:10])  # Print first 10 values\n",
    "    print(\"UTC Time:\", utc_time[:10])        # Print first 10 timestamps\n",
    "\n",
    "    movement = band_pass_filtering(data_stream, fs, \"bcg\")\n",
    "    print(\"Movement Signal:\", movement[:10])\n",
    "    # Create a time vector for plotting (in milliseconds)\n",
    "    time = np.arange(len(movement)) * (1000 / fs)\n",
    "\n",
    "    # Estimate heart rate using peak detection\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.signal import find_peaks\n",
    "\n",
    "    # def compute_rate(beats, time, mpd):\n",
    "    #     peaks, _ = find_peaks(beats, distance=mpd)\n",
    "    #     num_beats = len(peaks)\n",
    "    #     duration_in_seconds = (time[-1] - time[0]) / 1000\n",
    "    #     rate = (num_beats / duration_in_seconds) * 60  # bpm\n",
    "    #     return rate, peaks\n",
    "\n",
    "    mpd_samples = int(0.6 * fs)\n",
    "    heart_rate, peak_indices = compute_rate(movement, time, mpd_samples)\n",
    "\n",
    "    # Plot the filtered BCG signal with detected peaks\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(time, movement, label='Filtered BCG')\n",
    "    # Ensure peak_indices is not empty and is of integer type\n",
    "    if len(peak_indices) > 0:\n",
    "        plt.plot(time[peak_indices.astype(int)], movement[peak_indices.astype(int)], 'ro', label='Peaks')\n",
    "    else:\n",
    "        print(\"No peaks detected in the movement signal.\")\n",
    "    plt.title(f\"Detected BCG Peaks - Estimated Heart Rate: {heart_rate:.2f} bpm\")\n",
    "    plt.xlabel(\"Time (ms)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    breathing = band_pass_filtering(data_stream, fs, \"breath\")\n",
    "    print(\"Breathing Signal:\", breathing[:10])\n",
    "\n",
    "    # beats = vitals(t1, t2, window_shift, limit, wavelet_cycle, utc_time, mpd=1, plot=0)\n",
    "    print(\"Heart Rate Beats:\", beats)\n",
    "    print('\\nEnd processing ...')\n",
    "    # =================================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
